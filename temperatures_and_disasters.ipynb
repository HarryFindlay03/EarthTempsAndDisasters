{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import HDBSCAN, DBSCAN, KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "from helper_functions import distance_between_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "disasters_df = pd.read_csv('./datasets/public_emdat_disasters.csv')\n",
    "\n",
    "# disasters_df = disasters_df.copy()\n",
    "disasters_df['Year'] = disasters_df['DisNo.']\n",
    "disasters_df['Year'] = disasters_df['Year'].apply(lambda x: int((str(x).split(\"-\"))[0]))\n",
    "\n",
    "\n",
    "print(len(disasters_df['Latitude']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(disasters_df))\n",
    "non_historic_disasters_df = disasters_df[disasters_df['Historic'] == 'No']\n",
    "print(len(non_historic_disasters_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot again and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(disasters_df['Longitude'], disasters_df['Latitude'], label=\"Locations of disasters\", s=10)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Lat Long coordiantes of Disasters from 1900')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_historic_disasters_df['Total_Deaths'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plot showing the number of deaths per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the cumulative number of deaths per year\n",
    "years = [x for x in range(non_historic_disasters_df['Year'].min(), non_historic_disasters_df['Year'].max() + 1)]\n",
    "year_deaths_df = pd.DataFrame({'Year': years})\n",
    "year_deaths_df['Total_Deaths'] = non_historic_disasters_df.groupby(['Year'])['Total_Deaths'].sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting this value\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(year_deaths_df['Year'], year_deaths_df['Total_Deaths'], 'r-')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Deaths')\n",
    "plt.title('Plot Showing Number of Deaths Per Year for Non-Historical Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average deaths\n",
    "year_deaths_df['Average_Deaths'] = non_historic_disasters_df.groupby(['Year'])['Total_Deaths'].mean().values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(year_deaths_df['Year'], year_deaths_df['Average_Deaths'], 'r-')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Deaths')\n",
    "plt.title('Plot Showing Average Number of Deaths Per Year Per Disaster for Non-Historical Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this look like for historic data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average deaths\n",
    "years = [x for x in range(disasters_df['Year'].min(), disasters_df['Year'].max()+1)]\n",
    "\n",
    "year_deaths_df = pd.DataFrame({'Year': years})\n",
    "year_deaths_df['Historic_Average_Deaths'] = disasters_df.groupby(['Year'])['Total_Deaths'].mean().values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(year_deaths_df['Year'], year_deaths_df['Historic_Average_Deaths'], 'r-')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Deaths')\n",
    "plt.title('Plot Showing Average Number of Deaths Per Year Per Disaster for all Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that things are getting a lot safer as deaths are coming down.\n",
    "\n",
    "But can we look at the frequency of disasters per year, can this begin to tell us the affects of climate change on the natural world.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of disasters per year\n",
    "\n",
    "# using historic data\n",
    "years = [x for x in range(disasters_df['Year'].min(), disasters_df['Year'].max()+1)]\n",
    "\n",
    "freq_df = pd.DataFrame({'Year' : years})\n",
    "freq_df['Freq'] = disasters_df.groupby(['Year']).size().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting this data\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(freq_df['Year'], freq_df['Freq'], 'r-')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Disasters')\n",
    "plt.title('Number of Disasters Per Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same plot with data from start_year onwards\n",
    "start_year = 1950\n",
    "end_year = disasters_df['Year'].max() + 1\n",
    "years = [x for x in range(start_year, end_year)]\n",
    "\n",
    "non_historic_freq_df = pd.DataFrame({'Year' : years})\n",
    "non_historic_freq_df['Freq'] = disasters_df[disasters_df['Year'] >= start_year].groupby(['Year']).size().values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(non_historic_freq_df['Year'], non_historic_freq_df['Freq'], 'r-')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Disasters')\n",
    "plt.title(f'Natural Disasters Per Year {start_year} - {end_year}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this graph look like for non historic disasters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = non_historic_disasters_df['Year'].unique()\n",
    "non_historic_freq_df = pd.DataFrame({'Year' : years[1:]})\n",
    "non_historic_freq_df['Freq'] = non_historic_disasters_df[non_historic_disasters_df['Year'] > years[0]].groupby(['Year']).size().values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(non_historic_freq_df['Year'], non_historic_freq_df['Freq'], 'r-')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Disasters')\n",
    "plt.title(f'Natural Disasters Per Year {years[0]} - {years[-1]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Temperatures in the Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_df = pd.read_csv('./datasets/GlobalLandTemperaturesByCountry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping missed data to clean the dataset\n",
    "temps_clean_df = temps_df.dropna()\n",
    "\n",
    "# adding Year column\n",
    "temps_clean_df = temps_clean_df.copy()\n",
    "temps_clean_df['dt'] = pd.to_datetime(temps_clean_df['dt'])\n",
    "temps_clean_df['Year'] = temps_clean_df['dt'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting an average temperatue dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = temps_clean_df['Year'].unique()\n",
    "average_temperature_df = pd.DataFrame({'Year' : years})\n",
    "average_temperature_df['AverageTemperature'] = temps_clean_df.groupby(['Year'])['AverageTemperature'].mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting this data\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(average_temperature_df['Year'], average_temperature_df['AverageTemperature'], 'rx-', label='Average Temperature')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Average Temperature each Year')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a spike ... what is the reporting metrics like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = temps_clean_df['Year'].unique()\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Year' : years,\n",
    "    'NumReported' : [temps_clean_df[temps_clean_df['Year'] == year].size for year in years]\n",
    "    })\n",
    "\n",
    "metrics_df['Change'] = metrics_df['NumReported'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final year drastically drops off - we remove this row as it skews the plot\n",
    "metrics_df = metrics_df[metrics_df['Year'] != 2013]\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(metrics_df['Year'], metrics_df['NumReported'], 'r-', label='Reports per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Reports')\n",
    "plt.title('Number of Temperature Reports per Year')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(metrics_df['Year'], metrics_df['Change'], 'r-', label='Change of Number of Reports')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Change in Number of Reports')\n",
    "plt.title('Change of Number of Temperature Reports per Year')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above graphs - we can see that the reporting data only becomes stable after the year 1900 - therefore we can update the temps_clean_df for predicting temperatures to only include data after 1900."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Future Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_average_temperature_df = average_temperature_df[average_temperature_df['Year'] > 1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = stable_average_temperature_df[['Year']], stable_average_temperature_df['AverageTemperature']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "last_year = stable_average_temperature_df['Year'].min()\n",
    "years_ahead = [(last_year + (i * 10)) for i in range(16)]\n",
    "\n",
    "future_temperatures_df = pd.DataFrame({'Year' : years_ahead})\n",
    "future_temperatures_df['PredictedAverageTemperature'] = model.predict(future_temperatures_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(stable_average_temperature_df['Year'], stable_average_temperature_df['AverageTemperature'], 'ro', label='Average Temperature per Year')\n",
    "plt.plot(future_temperatures_df['Year'], future_temperatures_df['PredictedAverageTemperature'], 'gx--', label='Predicted Future Average Temperature per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Global Warming Affects')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Square Error: {mse}\")\n",
    "print(f\"Root Mean Square Error: {rmse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-Squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this data does a **Polynomial Regression** model fit better ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POLYNOMIAL MODEL\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2nd Order Polynomial\n",
    "poly2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly2_features = poly2.fit_transform(X_train)\n",
    "\n",
    "poly2_model = LinearRegression()\n",
    "poly2_model.fit(poly2_features, y_train)\n",
    "\n",
    "### 3rd Order Polynomial\n",
    "poly3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly3_features = poly3.fit_transform(X_train)\n",
    "\n",
    "poly3_model = LinearRegression()\n",
    "poly3_model.fit(poly3_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the accuracy of our new polynomial regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2nd Order\n",
    "poly2_years_ahead = poly2.fit_transform(np.asarray(years_ahead).reshape(-1, 1))\n",
    "poly2_predictions = poly2_model.predict(poly2_years_ahead)\n",
    "\n",
    "future_temperatures_poly2_df = pd.DataFrame({'Year' : years_ahead})\n",
    "future_temperatures_poly2_df['PredictedAverageTemperature'] = poly2_predictions\n",
    "\n",
    "### 3rd Order\n",
    "poly3_years_ahead = poly3.fit_transform(np.asarray(years_ahead).reshape(-1, 1))\n",
    "poly3_predictions = poly3_model.predict(poly3_years_ahead)\n",
    "\n",
    "future_temperatures_poly3_df = pd.DataFrame({'Year' : years_ahead})\n",
    "future_temperatures_poly3_df['PredictedAverageTemperature'] = poly3_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stable_average_temperature_df['Year'], stable_average_temperature_df['AverageTemperature'], 'ro', label='Average Temperature per Year')\n",
    "plt.plot(future_temperatures_poly2_df['Year'], future_temperatures_poly2_df['PredictedAverageTemperature'], 'gx--', label='Predicted Future Average Temperature per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Regression Model with Polynomial Degree 2')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stable_average_temperature_df['Year'], stable_average_temperature_df['AverageTemperature'], 'ro', label='Average Temperature per Year')\n",
    "plt.plot(future_temperatures_poly3_df['Year'], future_temperatures_poly3_df['PredictedAverageTemperature'], 'gx--', label='Predicted Future Average Temperature per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Regression Model with Polynomial Degree 3')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the accuracy of these models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2_test = poly2.fit_transform(X_test)\n",
    "poly3_test = poly3.fit_transform(X_test)\n",
    "\n",
    "poly2_test_predictions = poly2_model.predict(poly2_test)\n",
    "poly3_test_predictions = poly3_model.predict(poly3_test)\n",
    "\n",
    "poly2_mse = mean_squared_error(y_test, poly2_test_predictions)\n",
    "poly2_mae = mean_absolute_error(y_test, poly2_test_predictions)\n",
    "poly2_r2 = r2_score(y_test, poly2_test_predictions)\n",
    "\n",
    "poly3_mse = mean_squared_error(y_test, poly3_test_predictions)\n",
    "poly3_mae = mean_absolute_error(y_test, poly3_test_predictions)\n",
    "poly3_r2 = r2_score(y_test, poly3_test_predictions)\n",
    "\n",
    "print(f\"2nd Order Polynomial Regression\")\n",
    "print(f\"Mean Squared Error: {poly2_mse}\")\n",
    "print(f\"Mean Absolute Erorr: {poly2_mae}\")\n",
    "print(f\"R2 Score: {poly2_r2}\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(f\"3rd Order Polynomial Regression\")\n",
    "print(f\"Mean Squared Error: {poly3_mse}\")\n",
    "print(f\"Mean Absolute Erorr: {poly3_mae}\")\n",
    "print(f\"R2 Score: {poly3_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations with the Highest Number of Disasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locations with highest amount of disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1960\n",
    "end_year = disasters_df['Year'].max()\n",
    "\n",
    "years = [x for x in range(start_year, end_year)]\n",
    "\n",
    "start_year_disasters_df = disasters_df[disasters_df['Year'] >= start_year]\n",
    "\n",
    "countries = start_year_disasters_df['Country'].unique()\n",
    "amounts = []\n",
    "for country in countries:\n",
    "    amounts.append(len(start_year_disasters_df[start_year_disasters_df['Country'] == country]))\n",
    "\n",
    "country_amount_df = pd.DataFrame({'Country' : countries, 'Amount': amounts})\n",
    "\n",
    "# sort the dataframe based on frequency\n",
    "country_amount_df.sort_values(['Amount'], inplace=True, ascending=False)\n",
    "\n",
    "country_amount_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the top 10 values on a barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_country_amount_df = country_amount_df[:10]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_ten_country_amount_df['Amount'], y=top_ten_country_amount_df['Country'], hue=top_ten_country_amount_df['Country'], palette=\"viridis\")\n",
    "plt.title(\"Cumulative Number of Disasters per country\")\n",
    "plt.xlabel(\"Amount of Disasters\")\n",
    "plt.ylabel(\"Country\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies of Disasters per location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = country_amount_df['Country'].values\n",
    "\n",
    "frequencies_df = pd.DataFrame({'Country' : countries})\n",
    "\n",
    "frequencies = []\n",
    "for country in frequencies_df['Country']:\n",
    "    amounts_per_year = [x for x in start_year_disasters_df[start_year_disasters_df['Country'] == country].groupby(['Year']).size()]\n",
    "    frequencies.append(sum(amounts_per_year) / len(amounts_per_year))\n",
    "\n",
    "frequencies_df['Frequency'] = frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_frequencies_df = frequencies_df.sort_values(['Frequency'], ascending=False)[:10]\n",
    "\n",
    "# plotting these values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=plot_frequencies_df['Frequency'], y=plot_frequencies_df['Country'], hue=plot_frequencies_df['Country'], palette='viridis')\n",
    "plt.title(f\"Average Amount of Disasters per Year from {start_year}\")\n",
    "plt.xlabel(\"Amount of Disasters\")\n",
    "plt.ylabel(\"Country\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_frequencies_df = plot_frequencies_df.copy()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "pos = 1\n",
    "for country in top_frequencies_df['Country']:\n",
    "    temp_df = start_year_disasters_df[start_year_disasters_df['Country'] == country]\n",
    "    years =  temp_df['Year'].unique()\n",
    "    frequencies = temp_df.groupby(['Year']).size().values\n",
    "\n",
    "    plt.subplot(2, 5, pos)\n",
    "    plt.plot(years, frequencies, 'r-')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Amount of Disasters')\n",
    "    plt.title(f\"{country}\")\n",
    "    pos += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens now if we look at the temperature for this data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_frequencies_df = plot_frequencies_df.copy()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# changing country names that are different\n",
    "top_frequencies_df[top_frequencies_df['Country'] == \"United States of America\"] = \"United States\"\n",
    "top_frequencies_df[top_frequencies_df['Country'] == \"Russian Federation\"] = \"Russia\"\n",
    "top_frequencies_df[top_frequencies_df['Country'] == \"Democratic Republic of the Congo\"] = \"Congo (Democratic Republic Of The)\"\n",
    "\n",
    "pos = 1\n",
    "for country in top_frequencies_df['Country']:\n",
    "    temp_df = temps_clean_df[temps_clean_df['Country'] == country]\n",
    "\n",
    "\n",
    "    temp_df = temp_df[temp_df['Year'] >= start_year]\n",
    "    years =  temp_df['Year'].unique()\n",
    "    temperatures = temp_df.groupby(['Year'])['AverageTemperature'].mean().values\n",
    "\n",
    "    plt.subplot(2, 5, pos)\n",
    "    plt.plot(years, temperatures, 'b-')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Temperature')\n",
    "    plt.title(f\"{country}\")\n",
    "    pos += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Number of Deaths in a Disaster\n",
    "Using:\n",
    "- The average temperature for the year the disaster was in at the location\n",
    "- The magnitude of the disaster\n",
    "- The year that the disaster occured in\n",
    "- The magnitude scale - one hot encoded\n",
    "- The location of the disaster - one hot encoded\n",
    "- The disaster type - hot hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = pd.DataFrame()\n",
    "regression_df[['Year', 'Magnitude', 'Magnitude Scale', 'Total_Deaths', 'Total_Damage']] = start_year_disasters_df[['Year', 'Magnitude', 'Magnitude Scale', 'Total_Deaths', \"Total Damage ('000 US$)\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the average temperature for each location for the year the disaster was in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_temperatures = []\n",
    "for index, row in start_year_disasters_df.iterrows():\n",
    "    print(row['Year'])\n",
    "    average_temperatures.append(temps_clean_df[(temps_clean_df['Country'] == row['Country']) & (temps_clean_df['Year'] == row['Year'])]['AverageTemperature'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def check_location(df_main, row):\n",
    "    if type(row) is float:\n",
    "        return False\n",
    "    if row == \"Nationwide\":\n",
    "        return True\n",
    "    \n",
    "    row_locations = row.split(\",\")\n",
    "\n",
    "    for location in row_locations:\n",
    "        if location in df_main:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "country_deaths_per_year = []\n",
    "for index, row in start_year_disasters_df.iterrows():\n",
    "    print(row['Year'])\n",
    "    country_deaths_per_year.append(start_year_disasters_df[(start_year_disasters_df['Country'] == row['Country']) & (start_year_disasters_df['Year'] == row['Year'])]['Total_Deaths'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df['AverageTemperature'] = average_temperatures\n",
    "regression_df['TotalDeathsInCountryForYear'] = country_deaths_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **linear regression** model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data - getting rid of the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df.dropna(inplace=True)\n",
    "ranged_df.dropna(inplace=True)\n",
    "print(len(regression_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to have **Multiple Linear Regression Models** each for a type of disaster - 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalisation on required rows\n",
    "# regression_df['Year'] = (regression_df['Year'] - regression_df['Year'].min()) / (regression_df['Year'].max() - regression_df['Year'].min())\n",
    "# regression_df['TotalDeaths'] = (regression_df['TotalDeaths'] - regression_df['TotalDeaths'].min()) / (regression_df['TotalDeaths'].max() - regression_df['TotalDeaths'].min())\n",
    "# regression_df['TotalDeathsInCountryForYear'] = (regression_df['TotalDeathsInCountryForYear'] - regression_df['TotalDeathsInCountryForYear'].min()) / (regression_df['TotalDeathsInCountryForYear'].max() - regression_df['TotalDeathsInCountryForYear'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression_df['Magnitude Scale'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Richter Scale\n",
    "###\n",
    "scales = regression_df['Magnitude Scale'].unique()\n",
    "print(scales)\n",
    "\n",
    "for scale in scales:\n",
    "    richter_df = regression_df[regression_df['Magnitude Scale'] == scale]\n",
    "    # preprocessing richter model\n",
    "    richter_df = richter_df.copy()\n",
    "    richter_df.dropna(inplace=True)\n",
    "\n",
    "    print(f\"SCALE: {scale} \\t LENGTH: {len(richter_df)}\")\n",
    "\n",
    "    richter_df.drop('Magnitude Scale', axis=1, inplace=True)\n",
    "\n",
    "    # splitting\n",
    "    richter_X = richter_df.drop('Total_Deaths', axis=1)\n",
    "    richter_y = richter_df['Total_Deaths']\n",
    "\n",
    "    richter_X_train, richter_X_test, richter_y_train, richter_y_test = train_test_split(richter_X, richter_y, test_size=0.2, random_state=32)\n",
    "\n",
    "    richter_model = LinearRegression()\n",
    "\n",
    "    richter_model.fit(richter_X_train, richter_y_train)\n",
    "\n",
    "    richter_predictions = richter_model.predict(richter_X_train)\n",
    "\n",
    "    # richter_predictions = [0 if x < 0 else x for x in richter_predictions]\n",
    "\n",
    "    # Evaluating the accuracy of the model\n",
    "    print(f\"Mean Square Error: {mean_squared_error(richter_y_train, richter_predictions)}\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(richter_y_train, richter_predictions)}\")\n",
    "    print(f\"R2 Score: {r2_score(richter_y_train, richter_predictions)}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting magnitude against total deaths in a disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "index = 1\n",
    "for scale in scales:\n",
    "    scale_plot_df = regression_df[regression_df['Magnitude Scale'] == scale]\n",
    "    plt.subplot(2, 2, index)\n",
    "    plt.plot(scale_plot_df['Magnitude'], scale_plot_df['Total_Deaths'], 'ro')\n",
    "    plt.xlabel('Magnitude')\n",
    "    plt.ylabel('Total Deaths')\n",
    "    plt.title(f'Total Deaths in Disasters with Scale {scale}')\n",
    "    plt.grid(True)\n",
    "    index += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting average temperature in year with number of deaths in country in year ... this shows some interesting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "# note - range is really large\n",
    "# note - looking in the 25 to 30 range\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(regression_df['AverageTemperature'], regression_df['TotalDeathsInCountryForYear'], 'ro')\n",
    "plt.xlabel('Average Temperature')\n",
    "plt.ylabel('Total Deaths In Country Per Year')\n",
    "plt.grid(True)\n",
    "\n",
    "ranged_df = regression_df[(regression_df['TotalDeathsInCountryForYear'] <= 5000) & (regression_df['AverageTemperature'] >= 17)]\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(ranged_df['AverageTemperature'], ranged_df['TotalDeathsInCountryForYear'], 'ro')\n",
    "plt.xlabel('Average Temperature')\n",
    "plt.ylabel('Total Deaths In Country Per Year')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average temperature in the year and the number of disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_disaster_frequency = []\n",
    "for index, row in start_year_disasters_df.iterrows():\n",
    "    print(row['Year'])\n",
    "    country_disaster_frequency.append(len(start_year_disasters_df[(start_year_disasters_df['Country'] == row['Country']) & (start_year_disasters_df['Year'] == row['Year'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame({\n",
    "    'AverageTemperature' : average_temperatures,\n",
    "    'DisasterFreq' : country_disaster_frequency\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(plot_df['AverageTemperature'], plot_df['DisasterFreq'], alpha=0.2, s=3)\n",
    "plt.xlabel('Average Temperature')\n",
    "plt.ylabel('Number of Disasters Per Year')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a simple linear regression model look like on this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.dropna(inplace=True)\n",
    "\n",
    "# removing outliers from above graph - less than 10 avg temperature and number of disasters per year is greater than 20\n",
    "index_names = plot_df[(plot_df['AverageTemperature'] < 10) & (plot_df['DisasterFreq'] > 20)].index\n",
    "print(index_names)\n",
    "plot_df.drop(index_names, inplace=True)\n",
    "\n",
    "# linear model\n",
    "freq_X, freq_y = plot_df[['AverageTemperature']], plot_df['DisasterFreq']\n",
    "freq_X_train, freq_X_test, freq_y_train, freq_y_test = train_test_split(freq_X, freq_y, test_size=0.2)\n",
    "\n",
    "freq_model = LinearRegression()\n",
    "freq_model.fit(freq_X_train, freq_y_train)\n",
    "\n",
    "points_to_predict = np.asarray([x for x in range(int(plot_df[plot_df['AverageTemperature'] >= 0]['AverageTemperature'].min()), int(plot_df[plot_df['AverageTemperature'] >= 0]['AverageTemperature'].max()+1))]).reshape(-1, 1)\n",
    "predictions = freq_model.predict(points_to_predict)\n",
    "\n",
    "# polynomial model\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(freq_X_train)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(poly_features, freq_y_train)\n",
    "\n",
    "poly_points_to_predict = poly.fit_transform(points_to_predict)\n",
    "poly_predictions = poly_model.predict(poly_points_to_predict)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(plot_df['AverageTemperature'], plot_df['DisasterFreq'], alpha=0.2, s=3)\n",
    "plt.plot(points_to_predict, predictions, 'g--')\n",
    "plt.plot(points_to_predict, poly_predictions, 'r--')\n",
    "plt.xlabel('Average Temperature')\n",
    "plt.ylabel('Number of Disasters Per Year')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zoom in the plot\n",
    "plot_df = plot_df[(plot_df['AverageTemperature'] >= 0) & (plot_df['DisasterFreq'] <= 20)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(plot_df['AverageTemperature'], plot_df['DisasterFreq'], alpha=0.2, s=3)\n",
    "plt.plot(points_to_predict, predictions, 'g--', label='Linear Regression')\n",
    "plt.plot(points_to_predict, poly_predictions, 'r--', label='2nd Order Polynomial Regression')\n",
    "plt.xlabel('Average Temperature')\n",
    "plt.ylabel('Number of Disasters Per Year')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar ... !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "- Clustering based on the damage caused\n",
    "- Clustering based on the number of deaths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution of the number of deaths - using opacity to represent number of deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1960\n",
    "\n",
    "### CLEANING THE DATASET\n",
    "clustering_df = disasters_df[disasters_df['Year'] >= start_year]\n",
    "clustering_df = clustering_df.copy()\n",
    "clustering_df.dropna(subset=['Total_Deaths'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varying the opacity based on number of deaths\n",
    "\n",
    "# min-max scaling to put between 0 and 1 for opacity levels\n",
    "clustering_df['Total_Deaths_Scaled'] = (clustering_df['Total_Deaths'] - clustering_df['Total_Deaths'].min()) / (clustering_df['Total_Deaths'].max() - clustering_df['Total_Deaths'].min())\n",
    "\n",
    "clustering_df['Total_Deaths_per_10'] = (clustering_df['Total_Deaths'] / 10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame({\n",
    "    'Deaths' : clustering_df['Total_Deaths_per_10'].unique(),\n",
    "    'Freq' : clustering_df.groupby(['Total_Deaths_per_10']).size()\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(x=plot_df['Deaths'], y=plot_df['Freq'], s=10)\n",
    "plt.xlabel('Total Deaths per 10')\n",
    "plt.ylabel('Number of Occurences')\n",
    "plt.title('Lat Long coordiantes of Disasters from 1900')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plot_df = plot_df[plot_df['Deaths'] <= 30000]\n",
    "plt.scatter(x=plot_df['Deaths'], y=plot_df['Freq'], s=10)\n",
    "plt.xlabel('Total Deaths per 10')\n",
    "plt.ylabel('Number of Occurences')\n",
    "plt.title('Lat Long coordiantes of Disasters from 1900')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plot_df = plot_df[plot_df['Deaths'] <= 5000]\n",
    "plt.scatter(x=plot_df['Deaths'], y=plot_df['Freq'], s=10)\n",
    "plt.xlabel('Total Deaths per 10')\n",
    "plt.ylabel('Number of Occurences')\n",
    "plt.title('Lat Long coordiantes of Disasters from 1900')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(clustering_df['Longitude'], clustering_df['Latitude'], label=\"Locations of disasters\", s=15, alpha=0.05)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Lat Long coordiantes of Disasters from 1900')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping the opacity using the IQR of deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_df['Total_Deaths'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = clustering_df[(clustering_df['Total_Deaths'] >= 11) & (clustering_df['Total_Deaths'] <= 48)]\n",
    "\n",
    "plot_df = plot_df.copy()\n",
    "plot_df['Total_Deaths_Scaled'] = (plot_df['Total_Deaths'] - plot_df['Total_Deaths'].min()) / (plot_df['Total_Deaths'].max() - plot_df['Total_Deaths'].min())\n",
    "\n",
    "colors = plt.cm.Blues(np.arange(0.2,0.4,(1/len(plot_df['Total_Deaths_Scaled'])/5)))\n",
    "colors[:,-1] = plot_df['Total_Deaths_Scaled']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(plot_df['Longitude'], plot_df['Latitude'], label=\"Locations of disasters\", color=colors, s=15)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Lat Long coordiantes of Disasters from 1900 in the IQR of Deaths - Opacity representing number of Deaths')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DBScan vs HDBScan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN, HDBSCAN, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_X = clustering_df['Total_Deaths'].values.reshape(-1, 1)\n",
    "\n",
    "n_clusters = 8\n",
    "db = KMeans(n_clusters=n_clusters).fit(clustering_X)\n",
    "\n",
    "labels = db.labels_\n",
    "\n",
    "# n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "# n_noise = list(labels).count(-1)\n",
    "\n",
    "counts = [0] * n_clusters\n",
    "for label in set(labels):\n",
    "    for val in labels:\n",
    "        if label == val:\n",
    "            counts[label] += 1\n",
    "\n",
    "print(counts)\n",
    "\n",
    "print(f\"Number of Cluster: {n_clusters}\\t Number of Noise Points: {n_noise}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(clustering_df['Longitude'], clustering_df['Latitude'], label=\"Locations of disasters\", c=labels, cmap='inferno', s=5)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Lat Long coordiantes of Disasters from 1900')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Clustering ... DBSCAN / HDBSCAN on Distances from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN, HDBSCAN, KMeans\n",
    "from helper_functions import distance_between_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1960\n",
    "\n",
    "### CLEANING THE DATASET\n",
    "clustering_df = disasters_df[disasters_df['Year'] >= start_year]\n",
    "clustering_df = clustering_df.copy()\n",
    "clustering_df.dropna(subset=['Latitude', 'Longitude'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "for index, row in clustering_df.iterrows():\n",
    "    points.append(tuple([row['Longitude'], row['Latitude']]))\n",
    "\n",
    "\n",
    "clustering_X = np.asarray(points)\n",
    "db = DBSCAN(eps=3, min_samples=20).fit(clustering_X)\n",
    "\n",
    "labels = db.labels_\n",
    "\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise = list(labels).count(-1)\n",
    "\n",
    "print(f\"Number of Cluster: {n_clusters}\\t Number of Noise Points: {n_noise}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(clustering_df['Longitude'], clustering_df['Latitude'], label=\"Locations of disasters\", c=labels, cmap='Paired', s=5)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Lat Long coordiantes of Disasters from 1900')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
